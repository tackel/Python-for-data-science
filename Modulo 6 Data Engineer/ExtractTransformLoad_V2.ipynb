{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<center>\n    <img src=\"https://gitlab.com/ibm/skills-network/courses/placeholder101/-/raw/master/labs/module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# **Extract Transform Load (ETL) Lab**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Estimated time needed: **30** minutes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Read CSV and JSON file types.\n*   Extract data from the above file types.\n*   Transform data.\n*   Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Import the required modules and functions\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import glob                         # this module helps in selecting files \nimport pandas as pd                 # this module helps in processing CSV files\nimport xml.etree.ElementTree as ET  # this module helps in processing XML files.\nfrom datetime import datetime",
      "metadata": {},
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Download Files\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Unzip Files\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!unzip source.zip",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Set Paths\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tmpfile    = \"temp.tmp\"               # file used to store all extracted data\nlogfile    = \"logfile.txt\"            # all event logs will be stored in this file\ntargetfile = \"transformed_data.csv\"   # file where transformed data is stored",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Extract\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### CSV Extract Function\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def extract_from_csv(file_to_process):\n    dataframe = pd.read_csv(file_to_process)\n    return dataframe",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### JSON Extract Function\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def extract_from_json(file_to_process):\n    dataframe = pd.read_json(file_to_process,lines=True)\n    return dataframe",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### XML Extract Function\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def extract_from_xml(file_to_process):\n    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n    tree = ET.parse(file_to_process)\n    root = tree.getroot()\n    for person in root:\n        name = person.find(\"name\").text\n        height = float(person.find(\"height\").text)\n        weight = float(person.find(\"weight\").text)\n        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n    return dataframe",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Extract Function\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def extract():\n    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n    \n    #process all csv files\n    for csvfile in glob.glob(\"*.csv\"):\n        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n        \n    #process all json files\n    for jsonfile in glob.glob(\"*.json\"):\n        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n    \n    #process all xml files\n    for xmlfile in glob.glob(\"*.xml\"):\n        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n        \n    return extracted_data",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Transform\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The transform function does the following tasks.\n\n1.  Convert height which is in inches to millimeter\n2.  Convert weight which is in pounds to kilograms\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def transform(data):\n        #Convert height which is in inches to millimeter\n        #Convert the datatype of the column into float\n        #data.height = data.height.astype(float)\n        #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n        data['height'] = round(data.height * 0.0254,2)\n        \n        #Convert weight which is in pounds to kilograms\n        #Convert the datatype of the column into float\n        #data.weight = data.weight.astype(float)\n        #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n        data['weight'] = round(data.weight * 0.45359237,2)\n        return data",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Loading\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def load(targetfile,data_to_load):\n    data_to_load.to_csv(targetfile)  ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Logging\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def log(message):\n    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n    now = datetime.now() # get current timestamp\n    timestamp = now.strftime(timestamp_format)\n    with open(\"logfile.txt\",\"a\") as f:\n        f.write(timestamp + ',' + message + '\\n')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Running ETL Process\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "log(\"ETL Job Started\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "log(\"Extract phase Started\")\nextracted_data = extract()\nlog(\"Extract phase Ended\")\nextracted_data",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "log(\"Transform phase Started\")\ntransformed_data = transform(extracted_data)\nlog(\"Transform phase Ended\")\ntransformed_data ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "log(\"Load phase Started\")\nload(targetfile,transformed_data)\nlog(\"Load phase Ended\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "log(\"ETL Job Ended\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Exercise\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Using the example above complete the exercise below.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Download Files\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip",
      "metadata": {},
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "--2021-01-20 15:58:13--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\n\nResolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n\nConnecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n\nHTTP request sent, awaiting response... 200 OK\n\nLength: 4249 (4.1K) [application/zip]\n\nSaving to: ‘datasource.zip’\n\n\n\ndatasource.zip      100%[===================>]   4.15K  --.-KB/s    in 0.001s  \n\n\n\n2021-01-20 15:58:13 (8.09 MB/s) - ‘datasource.zip’ saved [4249/4249]\n\n\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Unzip Files\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!unzip datasource.zip -d dealership_data",
      "metadata": {},
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Archive:  datasource.zip\n\n  inflating: dealership_data/used_car_prices1.csv  \n\n  inflating: dealership_data/used_car_prices2.csv  \n\n  inflating: dealership_data/used_car_prices3.csv  \n\n  inflating: dealership_data/used_car_prices1.json  \n\n  inflating: dealership_data/used_car_prices2.json  \n\n  inflating: dealership_data/used_car_prices3.json  \n\n  inflating: dealership_data/used_car_prices1.xml  \n\n  inflating: dealership_data/used_car_prices2.xml  \n\n  inflating: dealership_data/used_car_prices3.xml  \n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## About the Data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Set Paths\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\nlogfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\ntargetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored",
      "metadata": {},
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Extract\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 1: CSV Extract Function\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Add the CSV extract function below\n",
      "metadata": {},
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```\n    \ndef extract_from_csv(file_to_process):\n    dataframe = pd.read_csv(file_to_process)\n    return dataframe\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 2: JSON Extract Function\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Add the JSON extract function below\n",
      "metadata": {},
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```\n    \ndef extract_from_json(file_to_process):\n    dataframe = pd.read_json(file_to_process,lines=True)\n    return dataframe\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 3: XML Extract Function\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Add the XML extract function below, it is the same as the xml extract function above but the column names need to be renamed.\n",
      "metadata": {},
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```\n    \ndef extract_from_xml(file_to_process):\n    dataframe = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel'])\n    tree = ET.parse(file_to_process)\n    root = tree.getroot()\n    for person in root:\n        car_model = person.find(\"car_model\").text\n        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n        price = float(person.find(\"price\").text)\n        fuel = person.find(\"fuel\").text\n        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n    return dataframe\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 4: Extract Function\n\nCall the specific extract functions you create above.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def extract():\n    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n    \n    #process all csv files\n    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n        \n    #process all json files\n    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n    \n    #process all xml files\n    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n        \n    return extracted_data",
      "metadata": {},
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```\n    \ndef extract():\n    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n    \n    #process all csv files\n    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n        \n    #process all json files\n    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n    \n    #process all xml files\n    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n        \n    return extracted_data\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Transform\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 5: Transform\n\nRound the `price` columns to 2 decimal places\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Add the transform function below\n",
      "metadata": {},
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```\n\ndef transform(data):\n        data['price'] = round(data.price, 2)\n        return data\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Loading\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 6: Load\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Add the load function below\n",
      "metadata": {},
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```\n\ndef load(targetfile,data_to_load):\n    data_to_load.to_csv(targetfile)  \n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Logging\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 7: Log\n\nMake sure to change the name of the logfile to the one specified in the set paths section. Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Add the log function below\n",
      "metadata": {},
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```\n\ndef log(message):\n    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n    now = datetime.now() # get current timestamp\n    timestamp = now.strftime(timestamp_format)\n    with open(\"dealership_logfile.txt\",\"a\") as f:\n        f.write(timestamp + ',' + message + '\\n') \n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Running ETL Process\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Question 8: ETL Process\n\nRun all functions to extract, transform, and load the data. Make sure to log all events using the `log` function. Place your code under each comment.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Log that you have started the ETL process\n\n\n# Log that you have started the Extract step\n\n# Call the Extract function\n\n# Log that you have completed the Extract step\n\n\n# Log that you have started the Transform step\n\n# Call the Transform function\n\n# Log that you have completed the Transform step\n\n\n# Log that you have started the Load step\n\n# Call the Load function\n\n# Log that you have completed the Load step\n\n\n# Log that you have completed the ETL process",
      "metadata": {},
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```\n\nlog(\"ETL Job Started\")\n\nlog(\"Extract phase Started\")\nextracted_data = extract()\nlog(\"Extract phase Ended\")\n\nlog(\"Transform phase Started\")\ntransformed_data = transform(extracted_data)\nlog(\"Transform phase Ended\")\n\nlog(\"Load phase Started\")\nload(targetfile,transformed_data)\nlog(\"Load phase Ended\")\n\nlog(\"ETL Job Ended\")\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ramesh Sannareddy\n\nJoseph Santarcangelo\n\nAzim Hirjani\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-11-25        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01&cm_mmc=Email_Newsletter-\\_-Developer_Ed%2BTech-\\_-WW_WW-\\_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n",
      "metadata": {}
    }
  ]
}